{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARK_HOME\"] = '/usr/local/Cellar/apache-spark/2.2.0/libexec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(os.environ['SPARK_HOME']+\"/python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.environ['SPARK_HOME']+\"/python/lib/py4j-0.10.4-src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py4j\n",
    "from pyspark import SparkContext, SparkConf, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[8]\")\n",
    "        .setAppName(\"ML demo\")\n",
    "        .set(\"spark.executor.memory\", \"2g\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionModel, LinearRegressionWithSGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a =LabeledPoint(0.0,[0.0, 1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 1.0, 2.0])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use ml.regression.LinearRegression.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928638123469\n"
     ]
    }
   ],
   "source": [
    "data=[\n",
    "    LabeledPoint(0.0,[0.0]),\n",
    "    LabeledPoint(1.0,[1.0]),\n",
    "    LabeledPoint(3.0,[2.0]),\n",
    "    LabeledPoint(2.0,[3.0])\n",
    "]\n",
    "lrm=LinearRegressionWithSGD.train(sc.parallelize(data),iterations=10,initialWeights=np.array([1.0]))\n",
    "print(lrm.predict(np.array([1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic dataset\n",
    "\n",
    "\n",
    "|**Variable**|Definition| Keys|\n",
    "|-------------------|-|-|\n",
    "|**survival**|\tSurvival|\t0 = No, 1 = Yes|\n",
    "|**pclass**\t|Ticket class|\t1 = 1st (upper), 2 = 2nd, 3 = 3rd (lower)|\n",
    "|**sex**|Sex|(male/female)|\n",
    "|**Age**|\tAge in years |Fractional if < 1. If the age is estimated -- in the form of xx.5\n",
    "|**sibsp**| # of siblings / spouses aboard the Titanic||\n",
    "|**parch**| # of parents / children aboard the Titanic||\n",
    "|**ticket**|Ticket number||\n",
    "|**fare**|Passenger fare (плата за проезд)||\n",
    "|**cabin**|Cabin number||\n",
    "|**embarked**|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf = pd.read_csv('titanic.csv')\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pdf['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "881          882         0       3    male  33.0      0      0   \n",
       "882          883         0       3  female  22.0      0      0   \n",
       "883          884         0       2    male  28.0      0      0   \n",
       "884          885         0       3    male  25.0      0      0   \n",
       "885          886         0       3  female  39.0      0      5   \n",
       "886          887         0       2    male  27.0      0      0   \n",
       "887          888         1       1  female  19.0      0      0   \n",
       "888          889         0       3  female   NaN      1      2   \n",
       "889          890         1       1    male  26.0      0      0   \n",
       "890          891         0       3    male  32.0      0      0   \n",
       "\n",
       "               Ticket     Fare Cabin Embarked  \n",
       "881            349257   7.8958   NaN        S  \n",
       "882              7552  10.5167   NaN        S  \n",
       "883  C.A./SOTON 34068  10.5000   NaN        S  \n",
       "884   SOTON/OQ 392076   7.0500   NaN        S  \n",
       "885            382652  29.1250   NaN        Q  \n",
       "886            211536  13.0000   NaN        S  \n",
       "887            112053  30.0000   B42        S  \n",
       "888        W./C. 6607  23.4500   NaN        S  \n",
       "889            111369  30.0000  C148        C  \n",
       "890            370376   7.7500   NaN        Q  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pdf.drop('Name', axis=1)\n",
    "#clean_data = pdf.drop('Ticket', axis=1)\n",
    "clean_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Companions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "5            6         0       3    male   NaN      0      0   \n",
       "6            7         0       1    male  54.0      0      0   \n",
       "7            8         0       3    male   2.0      3      1   \n",
       "8            9         1       3  female  27.0      0      2   \n",
       "9           10         1       2  female  14.0      1      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Companions  \n",
       "0         A/5 21171   7.2500   NaN        S           1  \n",
       "1          PC 17599  71.2833   C85        C           1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3            113803  53.1000  C123        S           1  \n",
       "4            373450   8.0500   NaN        S           0  \n",
       "5            330877   8.4583   NaN        Q           0  \n",
       "6             17463  51.8625   E46        S           0  \n",
       "7            349909  21.0750   NaN        S           4  \n",
       "8            347742  11.1333   NaN        S           2  \n",
       "9            237736  30.0708   NaN        C           1  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем новый столбец, чтобы посмотреть общее количество попутчиков пассажира (братья, сестры, жены, мужья + родители)\n",
    "clean_data['Companions'] = clean_data['SibSp'] + clean_data['Parch']\n",
    "clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в данных в колонках: Age (тип float, кстати), Cabin (ооочень много пропусков) и 2 пропуска в Embarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', nan, 'C123', nan, nan, 'E46', nan, nan, nan, 'G6',\n",
       "       'C103', nan, nan, nan, nan, nan, nan, nan, nan, nan, 'D56', nan,\n",
       "       'A6', nan, nan, nan, 'C23 C25 C27', nan, nan, nan, 'B78', nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'D33', nan, 'B30', 'C52', nan, nan, nan,\n",
       "       nan, nan, 'B28', 'C83', nan, nan, nan, 'F33', nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 'F G73', nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 'C23 C25 C27', nan, nan, nan, 'E31', nan, nan,\n",
       "       nan, 'A5', 'D10 D12', nan, nan, nan, nan, 'D26', nan, nan, nan, nan,\n",
       "       nan, nan, nan, 'C110', nan, nan, nan, nan, nan, nan, nan, 'B58 B60',\n",
       "       nan, nan, nan, nan, 'E101', 'D26', nan, nan, nan, 'F E69', nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'D47', 'C123', nan, 'B86', nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'F2', nan, nan, 'C2', nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 'E33', nan, nan,\n",
       "       nan, 'B19', nan, nan, nan, 'A7', nan, nan, 'C49', nan, nan, nan,\n",
       "       nan, nan, 'F4', nan, 'A32', nan, nan, nan, nan, nan, nan, nan, 'F2',\n",
       "       'B4', 'B80', nan, nan, nan, nan, nan, nan, nan, nan, nan, 'G6', nan,\n",
       "       nan, nan, 'A31', nan, nan, nan, nan, nan, 'D36', nan, nan, 'D15',\n",
       "       nan, nan, nan, nan, nan, 'C93', nan, nan, nan, nan, nan, 'C83', nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       'C78', nan, nan, 'D35', nan, nan, 'G6', 'C87', nan, nan, nan, nan,\n",
       "       'B77', nan, nan, nan, nan, 'E67', 'B94', nan, nan, nan, nan, 'C125',\n",
       "       'C99', nan, nan, nan, 'C118', nan, 'D7', nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, 'A19', nan, nan, nan, nan, nan, nan, 'B49', 'D', nan,\n",
       "       nan, nan, nan, 'C22 C26', 'C106', 'B58 B60', nan, nan, nan, 'E101',\n",
       "       nan, 'C22 C26', nan, 'C65', nan, 'E36', 'C54', 'B57 B59 B63 B66',\n",
       "       nan, nan, nan, nan, nan, nan, 'C7', 'E34', nan, nan, nan, nan, nan,\n",
       "       'C32', nan, 'D', nan, 'B18', nan, 'C124', 'C91', nan, nan, nan,\n",
       "       'C2', 'E40', nan, 'T', 'F2', 'C23 C25 C27', nan, nan, nan, 'F33',\n",
       "       nan, nan, nan, nan, nan, 'C128', nan, nan, nan, nan, 'E33', nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, 'D37', nan, nan, 'B35',\n",
       "       'E50', nan, nan, nan, nan, nan, nan, 'C82', nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, 'B96 B98', nan, nan, 'D36', 'G6',\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 'C78', nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, 'E10', 'C52', nan, nan, nan,\n",
       "       'E44', 'B96 B98', nan, nan, 'C23 C25 C27', nan, nan, nan, nan, nan,\n",
       "       nan, 'A34', nan, nan, nan, 'C104', nan, nan, 'C111', 'C92', nan,\n",
       "       nan, 'E38', 'D21', nan, nan, 'E12', nan, 'E63', nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, 'D', nan, 'A14', nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 'B49', nan, 'C93', 'B37', nan, nan, nan, nan,\n",
       "       'C30', nan, nan, nan, 'D20', nan, 'C22 C26', nan, nan, nan, nan,\n",
       "       nan, 'B79', 'C65', nan, nan, nan, nan, nan, nan, 'E25', nan, nan,\n",
       "       'D46', 'F33', nan, nan, nan, 'B73', nan, nan, 'B18', nan, nan, nan,\n",
       "       'C95', nan, nan, nan, nan, nan, nan, nan, nan, 'B38', nan, nan,\n",
       "       'B39', 'B22', nan, nan, nan, 'C86', nan, nan, nan, nan, nan, 'C70',\n",
       "       nan, nan, nan, nan, nan, 'A16', nan, 'E67', nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, 'C101', 'E25', nan, nan, nan,\n",
       "       nan, 'E44', nan, nan, nan, 'C68', nan, 'A10', nan, 'E68', nan,\n",
       "       'B41', nan, nan, nan, 'D20', nan, nan, nan, nan, nan, nan, nan,\n",
       "       'A20', nan, nan, nan, nan, nan, nan, nan, nan, nan, 'C125', nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, 'F4', nan, nan, 'D19', nan, nan,\n",
       "       nan, 'D50', nan, 'D9', nan, nan, 'A23', nan, 'B50', nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'B35', nan, nan, nan, 'D33', nan, 'A26',\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 'D48', nan,\n",
       "       nan, 'E58', nan, nan, nan, nan, nan, nan, 'C126', nan, 'B71', nan,\n",
       "       nan, nan, nan, nan, nan, nan, 'B51 B53 B55', nan, 'D49', nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'B5', 'B20', nan, nan, nan, nan, nan, nan,\n",
       "       nan, 'C68', 'F G63', 'C62 C64', 'E24', nan, nan, nan, nan, nan,\n",
       "       'E24', nan, nan, 'C90', 'C124', 'C126', nan, nan, 'F G73', 'C45',\n",
       "       'E101', nan, nan, nan, nan, nan, nan, 'E8', nan, nan, nan, nan, nan,\n",
       "       'B5', nan, nan, nan, nan, nan, nan, 'B101', nan, nan, 'D45', 'C46',\n",
       "       'B57 B59 B63 B66', nan, nan, 'B22', nan, nan, 'D30', nan, nan,\n",
       "       'E121', nan, nan, nan, nan, nan, nan, nan, 'B77', nan, nan, nan,\n",
       "       'B96 B98', nan, 'D11', nan, nan, nan, nan, nan, nan, 'E77', nan,\n",
       "       nan, nan, 'F38', nan, nan, 'B3', nan, 'B20', 'D6', nan, nan, nan,\n",
       "       nan, nan, nan, 'B82 B84', nan, nan, nan, nan, nan, nan, 'D17', nan,\n",
       "       nan, nan, nan, nan, 'B96 B98', nan, nan, nan, 'A36', nan, nan, 'E8',\n",
       "       nan, nan, nan, nan, nan, 'B102', nan, nan, nan, nan, 'B69', nan,\n",
       "       nan, 'E121', nan, nan, nan, nan, nan, 'B28', nan, nan, nan, nan,\n",
       "       nan, 'E49', nan, nan, nan, 'C47', nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, 'C92', nan, nan, nan, 'D28', nan, nan, nan, 'E17', nan,\n",
       "       nan, nan, nan, 'D17', nan, nan, nan, nan, 'A24', nan, nan, nan,\n",
       "       'D35', 'B51 B53 B55', nan, nan, nan, nan, nan, nan, 'C50', nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'B42', nan, 'C148', nan], dtype=object)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['Cabin'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlcontext.read.format(\n",
    "    'com.databricks.spark.csv').options(\n",
    "    header='true').load('/Users/MarinaAnanyeva/Downloads/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId='1', Survived='0', Pclass='3', Name='Braund, Mr. Owen Harris', Sex='male', Age='22', SibSp='1', Parch='0', Ticket='A', Fare='7.25', Cabin=None, Embarked='S')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='Q'), Row(Embarked='C'), Row(Embarked='S'), Row(Embarked='')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from pyspark.sql import types\n",
    "\n",
    "def Embarked_transform(x):\n",
    "    if x != None:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "my_udf = udf(Embarked_transform, types.StringType())\n",
    "df = df.withColumn('Embarked', my_udf(df['Embarked']))\n",
    "df.select('Embarked').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "df_t = encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string, EmbarkedIndex: double, EmbarkedVec: vector]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_age(str_age):\n",
    "    try:\n",
    "        return float(str_age)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transf(r):\n",
    "    return LabeledPoint(\n",
    "        int(r.Survived),\n",
    "        [\n",
    "            int(r.Pclass),\n",
    "            r.Sex == 'male',\n",
    "            float(r.Fare),\n",
    "            int(r.SibSp),\n",
    "            int(r.Parch),\n",
    "            parse_age(r.Age),\n",
    "        ] + list(r.EmbarkedVec.toArray())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df_t.rdd.map(transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[98] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "rfc = RandomForest.trainClassifier(train, numClasses=2,\n",
    "                             categoricalFeaturesInfo={},\n",
    "                            numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_new = RandomForest.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={}, numTrees= 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(m, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = rfc.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    errors = comp.map(lambda x: abs(x[0]-x[1]))\n",
    "    return 1-errors.sum()/errors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293650793650793"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(m, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = rfc_new.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    errors = comp.map(lambda x: abs(x[0]-x[1]))\n",
    "    return 1-errors.sum()/errors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373015873015873"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc_new, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hometask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# добавить 5 новых фичей (всего)\n",
    "# 3 фичи высчитываются из имеющихся\n",
    "# хотя бы одна использует udf (user defined function)\n",
    "\n",
    "# попробовать 3 новых модели\n",
    "\n",
    "# f-1 меру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score (среднее гармоническое)\n",
    "$F1 = \\frac{2 * Precision * Recall}{Precision + Recall} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lazy approach - from sklearn.metrics import f1_score\n",
    "\n",
    "# f-1 мера ручками\n",
    "def recall(true, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = true.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    true_positive = comp.map(lambda x: 1 if (x[0] == 1 == x[1]) else 0)\n",
    "    condition_condition_positive = comp.map(lambda x: 1 if (x[1] == 1) else 0)\n",
    "    return float(true_positive.sum())/condition_condition_positive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(true, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = true.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    true_positive = comp.map(lambda x: 1 if (x[0] == 1 == x[1]) else 0)\n",
    "    predicted_condition_positive = comp.map(lambda x: 1 if (x[0] == 1) else 0)\n",
    "    return float(true_positive.sum()) / predicted_condition_positive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(true, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = true.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    true_positive = comp.map(lambda x: 1 if (x[0] == 1 == x[1]) else 0)\n",
    "    condition_condition_positive = comp.map(lambda x: 1 if (x[1] == 1) else 0)\n",
    "    return float(true_positive.sum())/condition_condition_positive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(true, test):\n",
    "    return 2 * (recall(true, test) * precision(true, test)) / (recall(true, test) + precision(true, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485380116959064"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(rfc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7630057803468208"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(rfc_new, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 0. Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sex_transf(sex):\n",
    "    '''Function transforms sex into binary output\n",
    "    Input: string\n",
    "    Output: vector'''\n",
    "    if sex == 'male':\n",
    "        return 1\n",
    "    elif sex == 'female':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1.  Age\n",
    "We need the feature of 'age' to be non-negative\n",
    "That's why we use the function to get rid of zeroes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_age(str_age):\n",
    "    try:\n",
    "        return float(str_age)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2. Cabin type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#binary \n",
    "def parse_cabin(str_cabin):\n",
    "    return 0 if str_cabin == None else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print (parse_cabin(None))\n",
    "print (parse_cabin('123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#multi function\n",
    "def cabin_type(str_cabin):\n",
    "    if str_cabin == 'None':\n",
    "        return 0\n",
    "    elif str_cabin == '1':\n",
    "        return 1\n",
    "    elif str_cabin == '2':\n",
    "        return 2\n",
    "    elif str_cabin == '3':\n",
    "        return 3\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cabin_type(None))\n",
    "print(cabin_type('1'))\n",
    "print(cabin_type('2'))\n",
    "print(cabin_type('3'))\n",
    "print(cabin_type('123'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for 'Embarked' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='Q'), Row(Embarked='C'), Row(Embarked='S'), Row(Embarked='')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlcontext.read.format(\n",
    "    'com.databricks.spark.csv').options(\n",
    "    header='true').load('titanic.csv')\n",
    "def Embarked_transform(x):\n",
    "    if x != None:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "my_udf = udf(Embarked_transform, types.StringType())\n",
    "df = df.withColumn('Embarked', my_udf(df['Embarked']))\n",
    "df.select('Embarked').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for 'Ticket' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ticket='SC'),\n",
       " Row(Ticket='none'),\n",
       " Row(Ticket='SW'),\n",
       " Row(Ticket='WE'),\n",
       " Row(Ticket='SO'),\n",
       " Row(Ticket='SOTON'),\n",
       " Row(Ticket='W.'),\n",
       " Row(Ticket='S.C.'),\n",
       " Row(Ticket='SCO'),\n",
       " Row(Ticket='A.'),\n",
       " Row(Ticket='C.A.'),\n",
       " Row(Ticket='A'),\n",
       " Row(Ticket='S.O.'),\n",
       " Row(Ticket='W'),\n",
       " Row(Ticket='STON'),\n",
       " Row(Ticket='P'),\n",
       " Row(Ticket='S.W.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ticket_transform(x):\n",
    "    if '/' in x:\n",
    "        x = x.split('/')[0]\n",
    "        return x\n",
    "    return 'none'\n",
    "\n",
    "my_udf_ticket = udf(ticket_transform, types.StringType())\n",
    "df = df.withColumn('Ticket', my_udf_ticket(df['Ticket']))\n",
    "df.select('Ticket').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string, EmbarkedIndex: double, EmbarkedVec: vector]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "df_t = encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stringIndexer = StringIndexer(inputCol=\"Ticket\", outputCol=\"TicketIndex\")\n",
    "my_model = my_stringIndexer.fit(df_t)\n",
    "my_indexed = my_model.transform(df_t)\n",
    "my_encoder = OneHotEncoder(inputCol=\"TicketIndex\", outputCol=\"TicketVec\")\n",
    "my_df_t = my_encoder.transform(my_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_transf(r):\n",
    "    return LabeledPoint(\n",
    "        int(r.Survived),\n",
    "        [\n",
    "            int(r.Pclass),\n",
    "            r.Sex == 'male',\n",
    "            float(r.Fare),\n",
    "            int(r.SibSp),\n",
    "            int(r.Parch),\n",
    "            parse_age(r.Age),\n",
    "            int(len(r.Name)),  # 1\n",
    "            parse_cabin(r.Cabin) # 2\n",
    "        ] + list(r.EmbarkedVec.toArray()) \\\n",
    "          + list(r.TicketVec)  # 3 UDF\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId='1', Survived='0', Pclass='3', Name='Braund, Mr. Owen Harris', Sex='male', Age='22', SibSp='1', Parch='0', Ticket='A', Fare='7.25', Cabin=None, Embarked='S', EmbarkedIndex=0.0, EmbarkedVec=SparseVector(3, {0: 1.0}))]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId='1', Survived='0', Pclass='3', Name='Braund, Mr. Owen Harris', Sex='male', Age='22', SibSp='1', Parch='0', Ticket='A', Fare='7.25', Cabin=None, Embarked='S', EmbarkedIndex=0.0, EmbarkedVec=SparseVector(3, {0: 1.0}), TicketIndex=1.0, TicketVec=SparseVector(16, {1: 1.0}))]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df_t.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = my_df_t.rdd.map(my_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [3.0,1.0,7.25,1.0,0.0,22.0,23.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train, my_test = my_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2523] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train.cache()\n",
    "my_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [3.0,1.0,7.25,1.0,0.0,22.0,23.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,71.2833,1.0,0.0,38.0,51.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformation and filter for string variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different models testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionModel, LinearRegressionWithSGD\n",
    "from pyspark.mllib.classification import SVMWithSGD, NaiveBayes, LogisticRegressionWithSGD\n",
    "from pyspark.ml.classification import GBTClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'green'> #1 Naive Bayes </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_NaiveBayesModel = NaiveBayes.train(my_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.665625\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = my_train.map(lambda p: (my_NaiveBayesModel.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / my_train.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.45751633986928103\n"
     ]
    }
   ],
   "source": [
    "print('F1-score: ', f1_score(my_NaiveBayesModel, my_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'green'> #2 SVM with Stohastis Gradient Descent </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_SVMWithSGD = SVMWithSGD.train(my_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.6613924050632911\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel = my_train.map(lambda p: (my_SVMWithSGD.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / my_train.count()\n",
    "print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.6396761133603238\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: \", f1_score(my_SVMWithSGD, my_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color = 'green'> #3 Logistic Regression with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegressionWithSGD.train(my_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_acc(m, test):\n",
    "    predictionAndLabel = test.map(lambda p: (m.predict(p.features), p.label))\n",
    "    accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test.count()\n",
    "    print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.6023166023166023\n"
     ]
    }
   ],
   "source": [
    "my_acc(logreg_model, my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score:  0.6083650190114069\n"
     ]
    }
   ],
   "source": [
    "print('F1-score: ', f1_score(logreg_model, my_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
